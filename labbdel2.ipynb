{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cece0322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# U2 - Decision Trees med student-mat.csv\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa7b249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Läs in student-mat och skapa X (features) och y (tre betygsklasser)\n",
    "\n",
    "df = pd.read_csv(\"student-mat.csv\", sep=\";\")\n",
    "\n",
    "# Välj alla numeriska kolumner\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# X = alla numeriska kolumner UTOM G3 (slutbetyget)\n",
    "X = df[numeric_cols].drop(columns=[\"G3\"])\n",
    "\n",
    "# y = G3 omvandlat till tre klasser: low / medium / high\n",
    "bins = [-1, 9, 14, 20]\n",
    "labels = [\"low\", \"medium\", \"high\"]\n",
    "y = pd.cut(df[\"G3\"], bins=bins, labels=labels)\n",
    "\n",
    "print(\"Fördelning av klasser (y):\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nForm på X (rader, kolumner):\", X.shape)\n",
    "\n",
    "# Enkel visualisering: stapeldiagram över hur många i varje klass\n",
    "y.value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Antal elever per betygsklass (y)\")\n",
    "plt.xlabel(\"Klass\")\n",
    "plt.ylabel(\"Antal elever\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a48874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Funktion som kör ett beslutsträd-experiment många gånger (t.ex. 100)\n",
    "\n",
    "def run_decision_tree_experiment(X, y, test_size, normalize=False, n_runs=100):\n",
    "    \"\"\"\n",
    "    Kör DecisionTreeClassifier n_runs gånger med samma inställningar.\n",
    "\n",
    "    Varje gång:\n",
    "      - ny train/test-split\n",
    "      - ev. normalisering med MinMaxScaler\n",
    "      - DecisionTreeClassifier(random_state=None)\n",
    "      - beräknar accuracy och confusion matrix\n",
    "\n",
    "    Returnerar:\n",
    "      - mean_acc : medelaccuracy över alla körningar\n",
    "      - best_acc : bästa accuracy\n",
    "      - best_cm  : confusion matrix för körningen med bäst accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    accuracies = []\n",
    "    best_acc = -1\n",
    "    best_cm = None\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        # 1. Train/test-split (ingen random_state => ny slump varje gång)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=test_size,\n",
    "            stratify=y\n",
    "        )\n",
    "\n",
    "        # 2. Normalisera eller inte\n",
    "        if normalize:\n",
    "            scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "            X_train_used = scaler.fit_transform(X_train)\n",
    "            X_test_used = scaler.transform(X_test)\n",
    "        else:\n",
    "            X_train_used = X_train.values\n",
    "            X_test_used = X_test.values\n",
    "\n",
    "        # 3. Skapa beslutsträd (random_state=None enligt uppgiften)\n",
    "        clf = DecisionTreeClassifier(random_state=None)\n",
    "\n",
    "        # 4. Träna och predicera\n",
    "        clf.fit(X_train_used, y_train)\n",
    "        y_pred = clf.predict(X_test_used)\n",
    "\n",
    "        # 5. Accuracy + confusion matrix\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        # Spara bästa körningen (högst accuracy)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_cm = cm\n",
    "\n",
    "    mean_acc = np.mean(accuracies)\n",
    "    return mean_acc, best_acc, best_cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Kör alla experiment (4 stycken)\n",
    "\n",
    "# Två train/test-fördelningar:\n",
    "#  - 0.10 => 90% train, 10% test\n",
    "#  - 0.30 => 70% train, 30% test (vår \"välj själv\")\n",
    "splits = [\n",
    "    (0.10, \"train=90%, test=10%\"),\n",
    "    (0.30, \"train=70%, test=30%\")\n",
    "]\n",
    "\n",
    "# Två datatyper: original + normaliserat\n",
    "data_settings = [\n",
    "    (False, \"originaldata\"),\n",
    "    (True,  \"normaliserat [0,1]\")\n",
    "]\n",
    "\n",
    "dt_results = []  # lista där vi sparar resultaten\n",
    "\n",
    "for test_size, split_text in splits:\n",
    "    for normalize_flag, data_text in data_settings:\n",
    "        print(\"====================================================\")\n",
    "        print(f\"Experiment: {split_text}, data = {data_text}\")\n",
    "        print(\"Kör 100 gånger...\")\n",
    "\n",
    "        mean_acc, best_acc, best_cm = run_decision_tree_experiment(\n",
    "            X,\n",
    "            y,\n",
    "            test_size=test_size,\n",
    "            normalize=normalize_flag,\n",
    "            n_runs=100\n",
    "        )\n",
    "\n",
    "        print(f\"\\nMedelaccuracy över 100 körningar: {mean_acc:.4f}\")\n",
    "        print(f\"Bästa accuracy av 100 körningar: {best_acc:.4f}\")\n",
    "        print(\"Confusion matrix för bästa körningen (low, medium, high):\")\n",
    "        print(best_cm)\n",
    "\n",
    "        # Spara resultatet\n",
    "        dt_results.append({\n",
    "            \"Split\": split_text,\n",
    "            \"Test_size\": test_size,\n",
    "            \"Data_typ\": data_text,\n",
    "            \"Medelaccuracy\": mean_acc,\n",
    "            \"Bästa_accuracy\": best_acc,\n",
    "            \"Best_CM\": best_cm\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Tabell med alla Decision Tree-experiment (som Figur A2)\n",
    "\n",
    "dt_df = pd.DataFrame([\n",
    "    {\n",
    "        \"Split\": r[\"Split\"],\n",
    "        \"Data_typ\": r[\"Data_typ\"],\n",
    "        \"Medelaccuracy\": r[\"Medelaccuracy\"],\n",
    "        \"Bästa_accuracy\": r[\"Bästa_accuracy\"]\n",
    "    }\n",
    "    for r in dt_results\n",
    "])\n",
    "\n",
    "print(\"Alla Decision Tree-experiment:\")\n",
    "display(dt_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Hitta de tre bästa experimenten och visa confusion matrices\n",
    "\n",
    "dt_top3 = dt_df.sort_values(by=\"Medelaccuracy\", ascending=False).head(3)\n",
    "\n",
    "print(\"Tre bästa Decision Tree-experiment (sorterat efter medelaccuracy):\")\n",
    "display(dt_top3)\n",
    "\n",
    "print(\"\\nConfusion matrices för de tre bästa experimenten:\\n\")\n",
    "\n",
    "for i, row in dt_top3.reset_index(drop=True).iterrows():\n",
    "    split_text = row[\"Split\"]\n",
    "    data_text = row[\"Data_typ\"]\n",
    "    mean_acc = row[\"Medelaccuracy\"]\n",
    "\n",
    "    # Hitta motsvarande entry i dt_results för att få rätt confusion matrix\n",
    "    for r in dt_results:\n",
    "        if r[\"Split\"] == split_text and r[\"Data_typ\"] == data_text:\n",
    "            best_cm = r[\"Best_CM\"]\n",
    "            best_acc = r[\"Bästa_accuracy\"]\n",
    "            break\n",
    "\n",
    "    print(\"========================================\")\n",
    "    print(f\"Experiment {i+1}:\")\n",
    "    print(f\"Split: {split_text}\")\n",
    "    print(f\"Data: {data_text}\")\n",
    "    print(f\"Medelaccuracy (100 körningar): {mean_acc:.4f}\")\n",
    "    print(f\"Bästa accuracy av 100 körningar: {best_acc:.4f}\")\n",
    "    print(\"Confusion matrix (low, medium, high):\")\n",
    "    print(best_cm)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b903498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7 (extra): Visualisera ett beslutsträd\n",
    "\n",
    "# Vi väljer t.ex. 70/30, originaldata för att rita ett litet träd\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.30,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "# Träna ett grunt träd så att bilden blir läsbar\n",
    "clf_vis = DecisionTreeClassifier(random_state=None, max_depth=3)\n",
    "clf_vis.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plot_tree(\n",
    "    clf_vis,\n",
    "    feature_names=X.columns,\n",
    "    class_names=labels,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    fontsize=8\n",
    ")\n",
    "plt.title(\"Exempel på beslutsträd (max_depth=3)\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
